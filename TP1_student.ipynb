{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spinetools\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "root_directory = r\"D:\\Documents\\PolyMTL\\3D_reconstruction\\Lab_1\\Datafiles_LAB1\"\n",
    "view_0 = 'PA0'\n",
    "view_1 = 'LAT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "Please write the RMS calculation function here. You will need this function throughout the assignment, so craft it with care !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(reference:np.ndarray, prediction:np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates RMS\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reference : np.ndarray\n",
    "        Reference value\n",
    "    prediction : np.ndarray\n",
    "        Calculated/predicted value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        RMS metric\n",
    "    \"\"\"\n",
    "    if reference.shape != prediction.shape:\n",
    "        raise ValueError('Please provide arrays that are shaped the same ! Reference has shape {refshape} whereas prediction has shape {predshape}'.format(refshape = reference.shape, predshape = prediction.shape))\n",
    "    rms_value = 0.\n",
    "    if len(reference.shape) == 2: # Array of shape N, 3:\n",
    "        rms_value= np.sqrt(np.power(np.linalg.norm(reference-prediction, axis=1),2)).mean()\n",
    "    else: # Array of shape N, :\n",
    "        rms_value = np.sqrt(np.power(reference-prediction,2)).mean()\n",
    "    return rms_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.1\n",
    "Write the code for finding the over determined system matrix A. Then use the dlt function from spinetools.solver to extract the L parameters vector for each view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped A_4_1\n",
      "Dropped B_3_5\n"
     ]
    }
   ],
   "source": [
    "beads_data = spinetools.io.process_files(root_directory)\n",
    "# ? Filter out non redundant beads\n",
    "unique_beads = beads_data['2d']['bead'].tolist()\n",
    "unique_beads = [x.replace('C', 'A') for x in unique_beads]\n",
    "unique_beads = [x.replace('D', 'B') for x in unique_beads]\n",
    "\n",
    "# ? Count values\n",
    "value_count = {}\n",
    "for k in unique_beads:\n",
    "    if k in value_count.keys():\n",
    "        value_count[k] += 1\n",
    "    else:\n",
    "        value_count[k] = 1\n",
    "\n",
    "# ? Exclude the ones that aren't visible from everywhere\n",
    "for k, v in zip(list(value_count.keys()), list(value_count.values())):\n",
    "    if v == 1:\n",
    "        print('Dropped', k)\n",
    "        del value_count[k]\n",
    "\n",
    "unique_beads = list(value_count.keys())\n",
    "unique_beads.extend([x.replace('A', 'C') if 'A' in x else x.replace('B', 'D') for x in unique_beads])\n",
    "beads_data['2d'] = beads_data['2d'][beads_data['2d']['bead'].isin(unique_beads)]\n",
    "beads_data['3d'] = beads_data['3d'][beads_data['3d']['bead'].isin(unique_beads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spinetools.data import select_view, join_dataframes\n",
    "\n",
    "def get_a(view:str, data:dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Uses the view name and existing data for pre calculating the system matrix for calculating the 11 DLT coefficients\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    view : str\n",
    "        View name\n",
    "    data : dict\n",
    "        Data as a dict, with two keys ['2d', '3d']. Each key is associated to a table giving points location in 2d/3d, bead identifier and view name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A matrix, for the DLT\n",
    "    \"\"\"\n",
    "    A = []\n",
    "    joint_data = join_dataframes(select_view(data['2d'], view), data['3d'], 'bead')\n",
    "    # TODO : Using the equations from Appendix 1, write a function to turn pairs of 2D/3D beads data to an overdeterminated system.\n",
    "    # HINT 1 : we want to end up with some system AM = 0 where M is a vector containing [L0, L1... L10, 1]. So you just need to return A !\n",
    "    # HINT 2 : I gave you 'joint_data'. It's a dataframe, so check the columns names !\n",
    "\n",
    "    \n",
    "\n",
    "    return np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_view0 = spinetools.solver.dlt(get_a('Beads2D_'+view_0, beads_data))\n",
    "l_view1 = spinetools.solver.dlt(get_a('Beads2D_'+view_1, beads_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DLT parameters for %s : \"%view_0, l_view0)\n",
    "print(\"DLT parameters for %s : \"%view_1, l_view1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(dlt_params:np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Outputs a dictionnary containing the intrinsic and extrinsic parameters of the system based on the DLT parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dlt_params : np.ndarray\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dict with keys ['u0', 'v0', 'c_u', 'c_v', 'R', 'source_coordinates']\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    # TODO : Using the equations from Appendix 2, write a function to calculate intrinsic and extrinsic parameters of a system based on the DLT parameters\n",
    "    return out\n",
    "\n",
    "print('View %s :'%view_0)\n",
    "for k, v in get_parameters(l_view0).items():\n",
    "    print('\\t {variable} = {value}'.format(variable = k, value = v))\n",
    "print('-------------------------------------------------------------')\n",
    "print('View %s :'%view_1)\n",
    "for k, v in get_parameters(l_view1).items():\n",
    "    print('\\t {variable} = {value}'.format(variable = k, value = v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_3d_point(u0:float, v0:float, u1:float, v1:float, L0:np.ndarray, L1:np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates a 3D point from 2 2D coordinates pairs and L0 & L1 DLT calibration coefficients\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u0 : float\n",
    "        point 1 x-coordinate\n",
    "    v0 : float\n",
    "        point 1 y-coordinate\n",
    "    u1 : float\n",
    "        point 2 x-coordinate\n",
    "    v1 : float\n",
    "        point 2 y-coordinate\n",
    "    L0 : np.ndarray\n",
    "        DLT coefficients for view 1\n",
    "    L1 : np.ndarray\n",
    "        DLT coefficients for view 2\n",
    "    \"\"\"\n",
    "    A = []\n",
    "    # TODO : using Appendix A, write a function that takes 2 pairs of 2D coordinates and 2 11-parameters vectors as an input to return the corresponding 3D point. \n",
    "    # HINT 1 : It's the exact same problem as in question 1.1, but now the unknowns are x,y and z !\n",
    "    # HINT 2 : Refactor the pair of equation in order to have a 4 equations system (2 equations per view, 2 views) for finding a triplet of coordinates : AM = 0 where M = [x, y, z, 1]\n",
    "    return spinetools.solver.dlt(np.array(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spine = spinetools.structures.Spine(os.path.join(root_directory,'Vertebrae2D.mat'))\n",
    "colors = px.colors.qualitative.Alphabet\n",
    "fig = spinetools.render.Plot3D()\n",
    "\n",
    "for i, v_name in enumerate(spine.vertebrae):\n",
    "    # TODO : for each vertebra, calculate the location of each anatomical landmark and add its x,y,z coordinates to vert_x, vert_y, vert_z. Each vertebra will then be added to the 3D plot and plotted in the end.\n",
    "    vert = spine.get(v_name).data # Returns the vertebra data\n",
    "    \"\"\"\n",
    "    HINT : the data is a table containing the landmark name and the x,y coordinates for each view (so 5 columns)\n",
    "    HINT : Print the variable vert, and add a 'break' instruction to get out of the loop\n",
    "    For each vertebra, you should have 6 points. Each point is linked to 2 pairs of 2D coordinates, one in each view. These coordinates, with the two 11-DLT parameters will allow you to calculate the 3D position of the 6 anatomical landmarks on the vertebra.\n",
    "    \"\"\"\n",
    "    vert_x, vert_y, vert_z = [], [], []\n",
    "    \"\"\"\n",
    "    PSEUDOCODE\n",
    "    for each anatomical_landmark in vertebra_points:\n",
    "        x_point, y_point, z_point <- calculate_3d_point(anatomical_landmark, l_view0, l_view1)\n",
    "        Append x_point to vert_x\n",
    "        Append y_point to vert_y\n",
    "        Append z_point to vert_z\n",
    "    \"\"\"\n",
    "    fig.scatter_vertebrae(vert_x, vert_y, vert_z, v_name, colors[i]) # Adds the landmarks to the figure\n",
    "SPINE_3D_POINTS = fig.points # Access all the figure points as an array this way, will be useful in the rest of this assignment\n",
    "fig.show() # Shows the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I recommend you write a function that samples `n_beads` in the full set, and returns the subset. A code skeleton and some hints can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_beads(original_beads:dict, n_beads:int) -> dict:\n",
    "    \"\"\"\n",
    "    Samples n_beads beads from the original beads set\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_beads : dict\n",
    "        Dictionnary containing information on 2D and 3D position of the whole set of calibration beads\n",
    "    n_beads : int\n",
    "        Number of beads to select\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionnary containing information on 2D and 3D position of the subsampled of calibration beads\n",
    "    \"\"\"\n",
    "    output = deepcopy(original_beads) # ? First we deepcopy the original beads data, to avoid modifying it by mistake\n",
    "    selected_beads = []\n",
    "    \"\"\"\n",
    "    Let's modify our output until we reach the desired number of beads.\n",
    "    You want n beads sampled across both plates A & B (remember that plates C & D are just A & B rotated):\n",
    "    1. So you're gonna sample n_beads // 2 beads on plate A, and n_beads - (n_beads // 2) beads on plate B.\n",
    "    2. Add all these beads' names in the selected_beads list.\n",
    "    3. Then for each A & B bead, you want to add it's counterpart of plate C & D.\n",
    "    The selection step is already done :)\n",
    "    \"\"\"\n",
    "    output['2d'] = output['2d'][output['2d']['bead'].isin(selected_beads)].sort_values(by = 'bead', ignore_index = True)\n",
    "    output['3d'] = output['3d'][output['3d']['bead'].isin(selected_beads)].sort_values(by = 'bead', ignore_index = True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's increase the number of calibration beads gradually\n",
    "spine = spinetools.structures.Spine(os.path.join(root_directory,'Vertebrae2D.mat')) # Initialize the vertebrae structure\n",
    "\n",
    "# Create a dictionnary to store the results. Access a dictionnary key with brackets, for instance rms_measurements['x']\n",
    "rms_measurements = {\n",
    "        'x' : [],\n",
    "        'y' : [],\n",
    "        'z' : [],\n",
    "        '3d' : [],\n",
    "        'n_beads':[]\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "PSEUDOCODE\n",
    "computed_points_3d <- list\n",
    "for n_beads in [1...N], do:\n",
    "    beads_subset <- sample_n_beads(beads_data, n_beads)\n",
    "    A_view_0 <- get_a(view_0, beads_subset)\n",
    "    l_view_0 <- dlt(A_view_0)\n",
    "    A_view_1 <- get_a(view_1, beads_subset)\n",
    "    l_view_1 <- dlt(A_view_1)\n",
    "    for each vertebra in vertebrae:\n",
    "        for each anatomical_landmark in vertebra_points:\n",
    "        x_point, y_point, z_point <- calculate_3d_point(anatomical_landmark, l_view0, l_view1)\n",
    "        Append (x_point, y_point, z_point) to computed_points_3d\n",
    "    for each axis in ['x', ..., '3d']:\n",
    "        Append rms(SPINE_3D_POINTS, computed_points_3d) to rms_measurements[axis]\n",
    "        Append n_beads to rms_measurements['n_beads']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly interlude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here is a basic plotly example. Use it to plot your RMS values !\n",
    "\"\"\"\n",
    "fig = go.Figure()\n",
    "fig.update_layout(title = 'Various functions plot',\n",
    "                  yaxis_title = 'f(x)',\n",
    "                  xaxis_title = 'x')\n",
    "x_values = np.linspace(0, 10, 1001)\n",
    "y_values_0 = np.sin(x_values) * np.sin(2*x_values)\n",
    "y_values_1 = np.cos(x_values) * np.sin(0.5*np.power(x_values, 2))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = x_values,\n",
    "    y = y_values_0,\n",
    "    name = 'sin(x) * sin(2x)'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = x_values,\n",
    "    y = y_values_1,\n",
    "    name = 'cos(x) * sin(0.5 * x^2))'\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : On the same graph, plot all your RMS values wrt. the number of used calibration beads !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are 4 sets of 8 calibration beads. For each set, determine which one is which (same plate, small volume, medium volume, large volume) and plot calibration error curves.  \n",
    "Don't hesitate to use the function `plot_selected_beads` from `spinetools.render`to vizualize the selected beads to sort out the subsets !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_0 = ['A_1_6', 'A_4_6', 'A_1_2', 'A_4_2', 'B_1_5', 'B_5_5', 'B_1_1', 'B_5_1']\n",
    "set_1 = ['B_1_1', 'B_2_2', 'B_4_2', 'B_5_3', 'B_1_4', 'B_2_5', 'B_4_3', 'B_5_5']\n",
    "set_2 = ['A_1_4', 'A_2_4', 'A_1_5', 'A_2_5', 'B_1_3', 'B_2_3', 'B_1_4', 'B_2_4']\n",
    "set_3 = ['A_1_4', 'A_3_4', 'A_1_5', 'A_3_5', 'B_1_3', 'B_3_3', 'B_1_4', 'B_3_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : same thing as before, but now you have to select the provided beads ! Look at the function `sample_n_beads` from Q2.1 if you need some help on how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **small** calibration volume from previous question, plot reconstruction error with respect to the center of gravity of the calibration volume !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you have to code the function that allow us to add noise to the calibration beads coordinates. Hint : you should take a look at the documentation of `np.random.normal` :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_2d(original_beads:dict, std:float) -> dict:\n",
    "    \"\"\"\n",
    "    Adds noise to the 2D coordinates of the beads\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_beads : dict\n",
    "        Dictionnary containing information on 2D and 3D position of the a set of calibration beads\n",
    "    std : float\n",
    "        Standard deviation for the noise added.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Noised beads set\n",
    "    \"\"\"\n",
    "    output = deepcopy(original_beads) # ? First we deepcopy the original beads data, to avoid modifying it by mistake\n",
    "    # TODO : select 2D beads and add noise to them\n",
    "    \n",
    "    return output\n",
    "\n",
    "def add_noise_3d(original_beads:dict, std:float) -> dict:\n",
    "    \"\"\"\n",
    "    Adds noise to the 3D coordinates of the beads\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_beads : dict\n",
    "        Dictionnary containing information on 2D and 3D position of the a set of calibration beads\n",
    "    std : float\n",
    "        Standard deviation for the noise added.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Noised beads set\n",
    "    \"\"\"\n",
    "    output = deepcopy(original_beads) # ? First we deepcopy the original beads data, to avoid modifying it by mistake\n",
    "    # TODO : select 3D beads and add noise to them\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question is a bit tricky, as you have to get measurements for couples of values of standard deviation for 2D and 3D noise. A line plot is not very adapted for this, but we could use a heatmap ! Here is a small example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "heatmap = np.random.rand(11, 11)\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z = heatmap,\n",
    "        x = np.linspace(0., 10., 11),\n",
    "        y = np.linspace(0., 10., 11),\n",
    "        text = heatmap.round(2),\n",
    "        texttemplate=\"%{text}\",\n",
    "        colorscale='turbo'\n",
    "    ))\n",
    "fig.update_xaxes(title_text='Axis 1')\n",
    "fig.update_yaxes(title_text='Axis 2')\n",
    "fig.update_layout(title = 'Plot title')\n",
    "fig.update_traces(showscale=False)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbm6700e_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
